{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Mario Bros RL: CrossQ Demo\n",
                "\n",
                "This notebook trains a **CrossQ** agent (implemented via `sbx`'s SAC with modifications) on `SuperMarioBros-v0`.\n",
                "It is self-contained (requires `sbx` package from this repo) and includes all necessary wrappers."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 0. Colab Setup\n",
                "**Instructions:**\n",
                "1. **Git Push**: Ensure you have pushed your local changes (with `sbx` updates) to your GitHub fork.\n",
                "2. **Update URL**: Replace `YOUR_GITHUB_REPO_URL` below with the URL of your forked repository.\n",
                "3. **Run**: Execute the cell to install dependencies and the local package."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Install Dependencies\n",
                "import os\n",
                "\n",
                "# ==========================================\n",
                "# CHANGE THIS TO YOUR FORK URL\n",
                "YOUR_GITHUB_REPO_URL = \"https://github.com/martiincooper/RL-CROSSQ.git\"\n",
                "# ==========================================\n",
                "\n",
                "repo_name = YOUR_GITHUB_REPO_URL.split(\"/\")[-1].replace(\".git\", \"\")\n",
                "\n",
                "# 1. Clone if setup.py is missing and we aren't in the repo folder yet\n",
                "if not os.path.exists(\"setup.py\"):\n",
                "    if not os.path.exists(repo_name):\n",
                "        print(f\"Cloning {YOUR_GITHUB_REPO_URL}...\")\n",
                "        !git clone $YOUR_GITHUB_REPO_URL\n",
                "    \n",
                "    # Configure Python to work inside the repo\n",
                "    if os.path.exists(repo_name):\n",
                "        os.chdir(repo_name)\n",
                "        print(f\"Changed directory to {os.getcwd()}\")\n",
                "\n",
                "# 2. Install project in editable mode so 'sbx' is importable\n",
                "# We use --ignore-requires-python to bypass strict python checks\n",
                "# WE USE ABSOLUTE PATH to ensure pip finds it regardless of shell CWD\n",
                "cwd = os.getcwd()\n",
                "!pip install -e \"$cwd\" --ignore-requires-python\n",
                "\n",
                "# 3. Install compatible versions of libraries\n",
                "# gymnasium==0.29.1 is strict requirement for wrappers\n",
                "# numpy<2.0.0 is required for scipy and legacy gym compatibility\n",
                "# flax>=0.8.0 is required for compatibility with newer JAX versions\n",
                "# FORCE UNINSTALL TFP & DOPAMINE & NUMPY FIRST to remove Colab's stubborn pre-installed versions\n",
                "# PIN opencv-python<4.10.0 to avoid numpy>=2 requirement\n",
                "# USE --force-reinstall to ensure binaries match numpy version\n",
                "!pip uninstall -y tensorflow-probability dopamine-rl numpy\n",
                "!pip install --force-reinstall \"numpy<2.0.0\" \"flax>=0.8.0\" gymnasium==0.29.1 gym-super-mario-bros==7.4.0 nes-py==8.2.1 shimmy==1.3.0 \"opencv-python<4.10.0\" matplotlib stable-baselines3 tensorflow-probability==0.23.0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "\n",
                "# Ensure we can import sbx if we are in the cloned repo\n",
                "if os.getcwd() not in sys.path:\n",
                "    sys.path.append(os.getcwd())\n",
                "\n",
                "try:\n",
                "    import gymnasium as gym\n",
                "    from gymnasium.wrappers import ResizeObservation, GrayScaleObservation, FrameStack\n",
                "except ImportError as e:\n",
                "    print(\"ImportError:\", e)\n",
                "    print(\"Please install gymnasium==0.29.1: pip install gymnasium==0.29.1\")\n",
                "\n",
                "import gym_super_mario_bros\n",
                "from nes_py.wrappers import JoypadSpace\n",
                "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
                "import numpy as np\n",
                "import cv2\n",
                "import jax\n",
                "import optax\n",
                "import tensorflow_probability as tfp\n",
                "\n",
                "# Verify TFP JAX backend\n",
                "try:\n",
                "    tfd = tfp.substrates.jax.distributions\n",
                "    print(\"TFP JAX backend functional.\")\n",
                "except AttributeError:\n",
                "    print(\"Error: tensorflow_probability.substrates.jax not found. Please upgrade tensorflow-probability.\")\n",
                "\n",
                "try:\n",
                "    from sbx import SAC\n",
                "    from sbx.sac.utils import ReLU\n",
                "except ImportError:\n",
                "    print(\"Could not import sbx. Make sure you are running this notebook from the CrossQ repository root or have installed it via 'pip install -e .'\")\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "from stable_baselines3.common.monitor import Monitor\n",
                "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
                "\n",
                "# Ensure compatibility\n",
                "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
                "\n",
                "ENV_ID = 'SuperMarioBros-v0'\n",
                "TOTAL_TIMESTEPS = 100000 # Adjust as needed\n",
                "LOG_DIR = \"./mario_benchmark_logs/\"\n",
                "os.makedirs(LOG_DIR, exist_ok=True)\n",
                "\n",
                "print(f\"JAX Devices: {jax.devices()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Wrappers\n",
                "We define the environment wrappers here to make the notebook self-contained."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Robust wrapper to force Gymnasium API (5-tuple step)\n",
                "class MarioGymnasiumWrapper(gym.Wrapper):\n",
                "    def __init__(self, env):\n",
                "        # We manually wrap the gym environment\n",
                "        self.env = env\n",
                "        # Do not copy attributes manually, let Wrapper delegate or Properties handle it.\n",
                "        \n",
                "        # We try to get them from the unwrapped env if possible\n",
                "        # And convert to gymnasium spaces\n",
                "        gym_obs = env.observation_space\n",
                "        self._observation_space = gym.spaces.Box(\n",
                "            low=gym_obs.low, high=gym_obs.high, shape=gym_obs.shape, dtype=gym_obs.dtype\n",
                "        )\n",
                "        \n",
                "        gym_act = env.action_space\n",
                "        if hasattr(gym_act, 'n'):\n",
                "            self._action_space = gym.spaces.Discrete(gym_act.n)\n",
                "        else:\n",
                "             self._action_space = gym.spaces.Box(\n",
                "                low=gym_act.low, high=gym_act.high, shape=gym_act.shape, dtype=gym_act.dtype\n",
                "             )\n",
                "\n",
                "        self._metadata = getattr(env, 'metadata', {})\n",
                "        self._reward_range = getattr(env, 'reward_range', (-float('inf'), float('inf')))\n",
                "\n",
                "    @property\n",
                "    def action_space(self):\n",
                "        return self._action_space\n",
                "\n",
                "    @property\n",
                "    def observation_space(self):\n",
                "        return self._observation_space\n",
                "\n",
                "    @property\n",
                "    def metadata(self):\n",
                "        return self._metadata\n",
                "\n",
                "    @property\n",
                "    def reward_range(self):\n",
                "        return self._reward_range\n",
                "\n",
                "    def reset(self, **kwargs):\n",
                "        # gym-super-mario-bros reset returns (obs) or (obs, info) depending on version/wrapper\n",
                "        # Handle seed manually for old gym compatibility\n",
                "        seed = kwargs.get('seed', None)\n",
                "        options = kwargs.get('options', None)\n",
                "        \n",
                "        # Pop them to avoid passing to old reset which might not accept them\n",
                "        if 'seed' in kwargs: kwargs.pop('seed')\n",
                "        if 'options' in kwargs: kwargs.pop('options')\n",
                "        \n",
                "        if seed is not None:\n",
                "             try:\n",
                "                 self.env.seed(seed)\n",
                "             except AttributeError:\n",
                "                 pass # Env might not support seed\n",
                "        \n",
                "        # usage: obs = env.reset()\n",
                "        ret = self.env.reset(**kwargs)\n",
                "        if isinstance(ret, tuple):\n",
                "            if len(ret) == 2:\n",
                "                return ret\n",
                "            return ret[0], {}\n",
                "        return ret, {}\n",
                "\n",
                "    def step(self, action):\n",
                "        ret = self.env.step(action)\n",
                "        if len(ret) == 4:\n",
                "            obs, reward, done, info = ret\n",
                "            truncated = False\n",
                "            terminated = done\n",
                "            return obs, reward, terminated, truncated, info\n",
                "        elif len(ret) == 5:\n",
                "            return ret\n",
                "        else:\n",
                "            raise ValueError(f\"Unexpected step return length: {len(ret)}\")\n",
                "    \n",
                "    def render(self):\n",
                "        return self.env.render()\n",
                "    \n",
                "    def close(self):\n",
                "        return self.env.close()\n",
                "\n",
                "class ContinuousMarioWrapper(gym.ActionWrapper):\n",
                "    def __init__(self, env):\n",
                "        super().__init__(env)\n",
                "        n_actions = env.action_space.n\n",
                "        # CrossQ/SAC expect a Box action space\n",
                "        self.action_space = gym.spaces.Box(low=-1.0, high=1.0, shape=(n_actions,), dtype=np.float32)\n",
                "        \n",
                "    def action(self, action):\n",
                "        # Convert continuous vector to discrete index\n",
                "        return int(np.argmax(action))\n",
                "\n",
                "# Transpose to (H, W, C) = (84, 84, 4)\n",
                "class TransposeWrapper(gym.ObservationWrapper):\n",
                "    def __init__(self, env):\n",
                "        super().__init__(env)\n",
                "        old_shape = env.observation_space.shape # (4, 84, 84)\n",
                "        self.observation_space = gym.spaces.Box(\n",
                "            low=0, high=255, \n",
                "            shape=(old_shape[1], old_shape[2], old_shape[0]), \n",
                "            dtype=env.observation_space.dtype\n",
                "        )\n",
                "    \n",
                "    def observation(self, obs):\n",
                "        # obs is (4, 84, 84) -> (84, 84, 4)\n",
                "        return np.moveaxis(obs, 0, -1)\n",
                "\n",
                "def make_mario_env(env_id='SuperMarioBros-v0', action_space=SIMPLE_MOVEMENT, stack_frames=4, render_mode='rgb_array'):\n",
                "    # Create the original environment\n",
                "    # nes-py returns 4-tuple, gym 0.26 expects 5-tuple. compatibility=True might help.\n",
                "    env = gym_super_mario_bros.make(env_id, apply_api_compatibility=True) \n",
                "    env = JoypadSpace(env, action_space)\n",
                "    \n",
                "    # Force load (nes_py lazy initialization might be an issue)\n",
                "    env.reset()\n",
                "    \n",
                "    # Wrap it to gymnasium manually\n",
                "    env = MarioGymnasiumWrapper(env)\n",
                "\n",
                "    # Convert to continuous for CrossQ/SAC\n",
                "    env = ContinuousMarioWrapper(env)\n",
                "    \n",
                "    # Apply wrappers\n",
                "    env = GrayScaleObservation(env, keep_dim=False)\n",
                "    env = ResizeObservation(env, (84, 84))\n",
                "    env = FrameStack(env, stack_frames)\n",
                "    \n",
                "    env = TransposeWrapper(env)\n",
                "    \n",
                "    return env"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. CrossQ Configuration\n",
                "Configuration specific to CrossQ as per the paper."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_crossq_model(env, seed=1):\n",
                "    # CrossQ Hyperparameters\n",
                "    kwargs = {\n",
                "        \"verbose\": 1,\n",
                "        \"seed\": seed,\n",
                "        \"learning_starts\": 1000,\n",
                "        \"buffer_size\": 50_000, # Reduced to avoid OOM on laptop\n",
                "        \"ent_coef\": \"auto\",\n",
                "        \"crossq_style\": True,\n",
                "        \"policy_delay\": 3,\n",
                "        \"gradient_steps\": 1, # UTD=1\n",
                "        \"tau\": 1.0,          # No target network\n",
                "        \"learning_rate\": 1e-3,\n",
                "        \"policy_kwargs\": {\n",
                "             \"activation_fn\": ReLU,\n",
                "             \"n_critics\": 2,\n",
                "             \"batch_norm\": True,\n",
                "             \"batch_norm_momentum\": 0.99,\n",
                "             \"net_arch\": {\"pi\": [256, 256], \"qf\": [2048, 2048]}, # Wider critics for CrossQ\n",
                "             \"optimizer_kwargs\": {\"b1\": 0.5}\n",
                "        },\n",
                "    }\n",
                "\n",
                "    model = SAC(\n",
                "        \"CnnPolicy\", \n",
                "        env,\n",
                "        **kwargs\n",
                "    )\n",
                "    model.name = \"CrossQ\"\n",
                "    return model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training Loop\n",
                "Train the CrossQ agent."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create environments with Monitor\n",
                "env_crossq = Monitor(make_mario_env(ENV_ID), filename=os.path.join(LOG_DIR, \"CrossQ\"))\n",
                "\n",
                "# Initialize model\n",
                "model = create_crossq_model(env_crossq)\n",
                "\n",
                "print(f\"Training CrossQ for {TOTAL_TIMESTEPS} steps...\")\n",
                "model.learn(total_timesteps=TOTAL_TIMESTEPS, progress_bar=True)\n",
                "model.save(f\"sbx_CrossQ_mario\")\n",
                "print(f\"CrossQ Done.\")\n",
                "model.env.close()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Performance Check\n",
                "Plotting the learning curve."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def moving_average(values, window):\n",
                "    \"\"\"Smooth values by calculating moving average.\"\"\"\n",
                "    if len(values) < window:\n",
                "        return values\n",
                "    weights = np.repeat(1.0, window) / window\n",
                "    return np.convolve(values, weights, 'valid')\n",
                "\n",
                "def plot_results(log_folder, title='CrossQ Learning Curve'):\n",
                "    plt.figure(figsize=(10, 6))\n",
                "    algo = \"CrossQ\"\n",
                "    color = 'r'\n",
                "    \n",
                "    try:\n",
                "        if not os.path.exists(os.path.join(log_folder, f\"{algo}.monitor.csv\")):\n",
                "            print(f\"Log for {algo} not found.\")\n",
                "            return\n",
                "        \n",
                "        import pandas as pd\n",
                "        df = pd.read_csv(os.path.join(log_folder, f\"{algo}.monitor.csv\"), skiprows=1)\n",
                "        x = df['t'].values\n",
                "        y = df['r'].values\n",
                "        \n",
                "        if len(x) > 1:\n",
                "            y_smoothed = moving_average(y, window=50)\n",
                "            x_smoothed = x[len(x) - len(y_smoothed):]\n",
                "            plt.plot(x_smoothed, y_smoothed, label=algo, color=color)\n",
                "        else:\n",
                "            print(f\"Not enough data to plot for {algo}\")\n",
                "    except Exception as e:\n",
                "        print(f\"Could not plot {algo}: {e}\")\n",
                "            \n",
                "    plt.xlabel('Timesteps')\n",
                "    plt.ylabel('Episode Reward')\n",
                "    plt.title(title)\n",
                "    plt.legend()\n",
                "    plt.grid(True)\n",
                "    plt.show()\n",
                "\n",
                "plot_results(LOG_DIR)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Visual Demo (Watch it Play)\n",
                "Watch the trained CrossQ agent play."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_demo(model, env_id):\n",
                "    env = make_mario_env(env_id)\n",
                "    obs, _ = env.reset()\n",
                "    done = False\n",
                "    \n",
                "    print(\"Starting Demo! Check the popup window (or output below if on Colab).\")\n",
                "    \n",
                "    try:\n",
                "        from google.colab.patches import cv2_imshow\n",
                "        is_colab = True\n",
                "    except ImportError:\n",
                "        is_colab = False\n",
                "\n",
                "    try:\n",
                "        frames = []\n",
                "        # Run for a fixed number of frames\n",
                "        for _ in range(1000):\n",
                "            if done: break\n",
                "\n",
                "            action, _ = model.predict(obs, deterministic=True)\n",
                "            obs, reward, terminated, truncated, info = env.step(action)\n",
                "            done = terminated or truncated\n",
                "            \n",
                "            frame = env.render()\n",
                "            frame = np.ascontiguousarray(frame, dtype=np.uint8)\n",
                "            # Add label\n",
                "            cv2.putText(frame, \"CrossQ\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
                "            frames.append(frame)\n",
                "            \n",
                "            # Show basic animation attempt in non-colab, or just collect frames for colab video (not implemented here since user just wants to \"see\" it)\n",
                "            if not is_colab:\n",
                "                # BGR for opencv\n",
                "                f_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
                "                cv2.imshow(\"CrossQ Mario\", f_bgr)\n",
                "                if cv2.waitKey(20) & 0xFF == ord('q'):\n",
                "                    break\n",
                "        \n",
                "        print(f\"Demo finished. Episode Length: {len(frames)} frames\")\n",
                "        \n",
                "        # If you really want to see it in Colab, saving a video is best\n",
                "        if is_colab and len(frames) > 0:\n",
                "             print(\"Saving video to 'crossq_demo.mp4'...\")\n",
                "             height, width, layers = frames[0].shape\n",
                "             # Use mp4v codec for compatibility\n",
                "             out = cv2.VideoWriter('crossq_demo.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 30, (width, height))\n",
                "             for f in frames:\n",
                "                 out.write(cv2.cvtColor(f, cv2.COLOR_RGB2BGR))\n",
                "             out.release()\n",
                "             print(\"Video saved! Download 'crossq_demo.mp4' to view.\")\n",
                "\n",
                "    finally:\n",
                "        env.close()\n",
                "        if not is_colab:\n",
                "            cv2.destroyAllWindows()\n",
                "            cv2.waitKey(1)\n",
                "\n",
                "run_demo(model, ENV_ID)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}