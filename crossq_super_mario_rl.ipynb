{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CrossQ on Super-Mario-RL (Replicated)\n",
                "\n",
                "This notebook runs **CrossQ** on the Super-Mario-RL environment.\n",
                "To ensure stability and simplicity, we replicate the environment stack (Noop, Skip, EpisodicLife, Warp, Stack) from `Super-Mario-RL` natively in **Gymnasium**, avoiding legacy dependency conflicts."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 0. Setup\n",
                "1. **Git Push** your sbx changes.\n",
                "2. **Run** the setup cell."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Install Dependencies\n",
                "import os\n",
                "\n",
                "# ==========================================\n",
                "# YOUR FORK\n",
                "YOUR_GITHUB_REPO_URL = \"https://github.com/martiincooper/RL-CROSSQ.git\"\n",
                "# ==========================================\n",
                "\n",
                "# 1. Clone CrossQ\n",
                "repo_name = YOUR_GITHUB_REPO_URL.split(\"/\")[-1].replace(\".git\", \"\")\n",
                "if not os.path.exists(\"setup.py\"):\n",
                "    if not os.path.exists(repo_name):\n",
                "        !git clone $YOUR_GITHUB_REPO_URL\n",
                "    if os.path.exists(repo_name):\n",
                "        os.chdir(repo_name)\n",
                "\n",
                "# 2. Clone Super-Mario-RL (For reference/assets)\n",
                "if not os.path.exists(\"Super-Mario-RL\"):\n",
                "    !git clone https://github.com/jiseongHAN/Super-Mario-RL.git\n",
                "\n",
                "# 3. Install SBX\n",
                "cwd = os.getcwd()\n",
                "!pip install -e \"$cwd\" --ignore-requires-python\n",
                "\n",
                "# 4. Install Dependencies (Shimmy = Bridge from Old Gym -> Gymnasium)\n",
                "!pip uninstall -y jax jaxlib tensorflow-probability dopamine-rl numpy\n",
                "!pip install \"numpy<2.0.0\" \"shimmy>=1.3.0\" \"gym-super-mario-bros==7.4.0\" \"nes-py==8.2.1\" \"opencv-python<4.10.0\" matplotlib stable-baselines3\n",
                "!pip install -U \"jax[cuda12_pip]==0.4.28\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
                "!pip install tensorflow-probability==0.23.0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import jax\n",
                "import numpy as np\n",
                "import gymnasium as gym\n",
                "import shimmy\n",
                "import gym_super_mario_bros\n",
                "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
                "from nes_py.wrappers import JoypadSpace\n",
                "from sbx import SAC\n",
                "from sbx.sac.utils import ReLU\n",
                "from stable_baselines3.common.monitor import Monitor\n",
                "from stable_baselines3.common.atari_wrappers import NoopResetEnv, MaxAndSkipEnv, WarpFrame\n",
                "from gymnasium.wrappers import FrameStack\n",
                "\n",
                "# Prevent JAX memory issues\n",
                "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
                "\n",
                "# === Replicating Super-Mario-RL Wrappers in Gymnasium ===\n",
                "\n",
                "class EpisodicLifeMario(gym.Wrapper):\n",
                "    \"\"\"Re-implementation of EpisodicLifeEnv for Mario (Gymnasium)\"\"\"\n",
                "    def __init__(self, env):\n",
                "        super().__init__(env)\n",
                "        self.lives = 0\n",
                "        self.was_real_done = True\n",
                "\n",
                "    def step(self, action):\n",
                "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
                "        self.was_real_done = terminated or truncated\n",
                "        \n",
                "        # The shimmy wrapped env puts the original env in `.unwrapped`\n",
                "        # nes-py env property is `_life`\n",
                "        lives = self.env.unwrapped._life\n",
                "        \n",
                "        if lives < self.lives and lives > 0:\n",
                "            terminated = True\n",
                "            \n",
                "        self.lives = lives\n",
                "        return obs, reward, terminated, truncated, info\n",
                "\n",
                "    def reset(self, **kwargs):\n",
                "        if self.was_real_done:\n",
                "            obs, info = self.env.reset(**kwargs)\n",
                "        else:\n",
                "            # No-op step to advance\n",
                "            obs, _, _, _, info = self.env.step(0)\n",
                "            \n",
                "        self.lives = self.env.unwrapped._life\n",
                "        return obs, info\n",
                "\n",
                "class ContinuousToDiscreteWrapper(gym.ActionWrapper):\n",
                "    \"\"\"Adapts CrossQ (Continuous) -> Mario (Discrete)\"\"\"\n",
                "    def __init__(self, env):\n",
                "        super().__init__(env)\n",
                "        self.n = env.action_space.n\n",
                "        self.action_space = gym.spaces.Box(low=-1.0, high=1.0, shape=(self.n,), dtype=np.float32)\n",
                "    \n",
                "    def action(self, action):\n",
                "        return int(np.argmax(action))\n",
                "\n",
                "def make_mario_env_replicated():\n",
                "    # 1. Base Env (Old Gym)\n",
                "    env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
                "    env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
                "    \n",
                "    # 2. Convert to Gymnasium (Shimmy)\n",
                "    env = shimmy.GymV21CompatibilityV0(env=env)\n",
                "    \n",
                "    # 3. Apply Replicated Wrappers (Order matters! Matches wrap_mario)\n",
                "    env = NoopResetEnv(env, noop_max=30)\n",
                "    env = MaxAndSkipEnv(env, skip=4)\n",
                "    env = EpisodicLifeMario(env)\n",
                "    env = WarpFrame(env) # 84x84 Grayscale\n",
                "    # ClipRewardEnv is NOT used in wrap_mario from the repo\n",
                "    # ScaledFloatFrame is implicitly handled or we can add\n",
                "    # SB3 WarpFrame returns uint8 0-255 generally. \n",
                "    # CrossQ usually wants 0-1 floats? SBX CNN policy handles normalization often. \n",
                "    # Let's verify: NatureCNN in SB3 divides by 255. SBX uses same structure.\n",
                "    # So uint8 0-255 is CORRECT for standard CnnPolicy.\n",
                "    \n",
                "    env = FrameStack(env, 4)\n",
                "    \n",
                "    # 4. Agent Adapter\n",
                "    env = ContinuousToDiscreteWrapper(env)\n",
                "    \n",
                "    return env"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Train CrossQ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "LOG_DIR = \"./mario_replicated_logs/\"\n",
                "os.makedirs(LOG_DIR, exist_ok=True)\n",
                "\n",
                "env = Monitor(make_mario_env_replicated(), filename=os.path.join(LOG_DIR, \"CrossQ\"))\n",
                "\n",
                "kwargs = {\n",
                "    \"verbose\": 1,\n",
                "    \"learning_starts\": 1000,\n",
                "    \"buffer_size\": 50_000,\n",
                "    \"ent_coef\": \"auto\",\n",
                "    \"crossq_style\": True,\n",
                "    \"policy_delay\": 3,\n",
                "    \"gradient_steps\": 1,\n",
                "    \"tau\": 1.0,\n",
                "    \"learning_rate\": 1e-3,\n",
                "    \"policy_kwargs\": {\n",
                "            \"activation_fn\": ReLU,\n",
                "            \"n_critics\": 2,\n",
                "            \"batch_norm\": True,\n",
                "            \"net_arch\": {\"pi\": [256, 256], \"qf\": [2048, 2048]},\n",
                "            \"optimizer_kwargs\": {\"b1\": 0.5}\n",
                "    },\n",
                "}\n",
                "\n",
                "model = SAC(\"CnnPolicy\", env, **kwargs)\n",
                "\n",
                "print(\"Training CrossQ on Super-Mario-RL stack...\")\n",
                "model.learn(total_timesteps=100000, progress_bar=True)\n",
                "model.save(\"crossq_super_mario_replicated\")\n",
                "print(\"Done.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}